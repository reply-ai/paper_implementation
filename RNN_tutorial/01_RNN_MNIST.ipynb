{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T14:38:56.844814Z",
     "start_time": "2019-01-15T14:38:51.341309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"PACKAGES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T14:39:30.301687Z",
     "start_time": "2019-01-15T14:39:19.778916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8f7ccd08229d>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jwserver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "MNIST LOADED\n",
      "TF VERSION 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST\n",
    "\n",
    "MNIST = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "trainimgs, trainlabels, testimgs, testlabels \\\n",
    "    = MNIST.train.images, MNIST.train.labels, MNIST.test.images, MNIST.test.labels\n",
    "ntrain, ntest, dim, nclasses \\\n",
    "    = trainimgs.shape[0], testimgs.shape[0], trainimgs.shape[1], trainlabels.shape[1]\n",
    "print(\"MNIST LOADED\")\n",
    "print(\"TF VERSION %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T14:40:14.337721Z",
     "start_time": "2019-01-15T14:40:14.291538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "diminput = 28\n",
    "dimhidden = 128\n",
    "dimoutput = nclasses\n",
    "nsteps = 28\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([diminput, dimhidden])),\n",
    "    'out': tf.Variable(tf.random_normal([dimhidden, dimoutput]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([dimhidden])),\n",
    "    'out': tf.Variable(tf.random_normal([dimoutput]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:03:47.222319Z",
     "start_time": "2019-01-16T04:03:47.212803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION READY\n"
     ]
    }
   ],
   "source": [
    "def _RNN(_X, _istate, _W, _b, _nsteps, _name):\n",
    "    # 1. PERMUTE INPUT FROM [batchsize, nsteps, diminput]\n",
    "    #     TO [nsteps, batchsize, diminput]\n",
    "    _X = tf.transpose(_X, [1, 0, 2])    # j x k x i\n",
    "    # 2. RESHAPE INPUT TO [nsteps*batchsize, diminput]\n",
    "    _X = tf.reshape(_X, [-1, diminput])\n",
    "    # 3. INPUT TO HIDDEN LAYER\n",
    "    _H = tf.matmul(_X, _W['hidden']) + _b['hidden']\n",
    "    # 4. SPLIT DATA TO 'NSTEPS' CHUNKS => LIST\n",
    "    _Hsplit = tf.split(_H, _nsteps, axis=0)\n",
    "    # 5. GET LSTM'S FINAL OUTPUT (_LSTM_O) AND STATE (_LSTM_S)\n",
    "    with tf.variable_scope(_name):\n",
    "        # RNN <= TF.CONTRIB.RNN\n",
    "        lstm_cell = rnn.BasicLSTMCell(\n",
    "            dimhidden, forget_bias=1.0, state_is_tuple=False)\n",
    "        _LSTM_O, _LSTM_S = rnn.static_rnn(\n",
    "            lstm_cell, _Hsplit, initial_state=_istate)\n",
    "    # OUTPUT\n",
    "    _O = tf.matmul(_LSTM_O[-1], _W['out']) + _b['out']\n",
    "    return {\n",
    "        'X': _X, 'H': _H, 'Hsplit': _Hsplit,\n",
    "        'LSTM_O': _LSTM_O, 'LSTM_S': _LSTM_S, 'O': _O\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"FUNCTION READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:04:05.582481Z",
     "start_time": "2019-01-16T04:04:03.933454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-73237078b71e>:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7faa74a60dd8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:From <ipython-input-5-3dfa5dabe3c3>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "NETWORK READY\n"
     ]
    }
   ],
   "source": [
    "# Define Graph\n",
    "learning_rate = 0.001\n",
    "x = tf.placeholder(\"float\", [None, nsteps, diminput])\n",
    "istate = tf.placeholder(\"float\", [None, 2*dimhidden])\n",
    "# state & cell => 2x n_hidden\n",
    "y = tf.placeholder(\"float\", [None, dimoutput])\n",
    "myrnn = _RNN(x, istate, weights, biases, nsteps, 'basic')\n",
    "pred = myrnn['O']\n",
    "celoss = tf.nn.softmax_cross_entropy_with_logits\n",
    "cost = tf.reduce_mean(celoss(logits=pred, labels=y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "accr = tf.reduce_mean(\n",
    "    tf.cast(tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)), tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "print(\"NETWORK READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:04:21.551978Z",
     "start_time": "2019-01-16T04:04:20.397172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "training_epochs = 5\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:05:13.039128Z",
     "start_time": "2019-01-16T04:04:40.966573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START OPTIMIZATION.\n",
      "EPOCH: 000/005 COST: 0.513487184\n",
      " TRAIN ACCURACY: 0.930\n",
      "  TEST ACCURACY: 0.941\n",
      "EPOCH: 001/005 COST: 0.131504879\n",
      " TRAIN ACCURACY: 0.945\n",
      "  TEST ACCURACY: 0.955\n",
      "EPOCH: 002/005 COST: 0.085917361\n",
      " TRAIN ACCURACY: 0.984\n",
      "  TEST ACCURACY: 0.968\n",
      "EPOCH: 003/005 COST: 0.064737575\n",
      " TRAIN ACCURACY: 0.992\n",
      "  TEST ACCURACY: 0.969\n",
      "EPOCH: 004/005 COST: 0.052588019\n",
      " TRAIN ACCURACY: 0.969\n",
      "  TEST ACCURACY: 0.978\n",
      "OPTIMIZATION FINISHED.\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "print(\"START OPTIMIZATION.\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(MNIST.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = MNIST.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape((batch_size, nsteps, diminput))\n",
    "        # Fit training using batch data\n",
    "        feeds = {x: batch_xs, y: batch_ys,\n",
    "                 istate: np.zeros((batch_size, 2*dimhidden))}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)/total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"EPOCH: %03d/%03d COST: %.9f\" %\n",
    "              (epoch, training_epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys,\n",
    "                 istate: np.zeros((batch_size, 2*dimhidden))}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print(\" TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        testimgs = testimgs.reshape((ntest, nsteps, diminput))\n",
    "        feeds = {x: testimgs, y: testlabels,\n",
    "                 istate: np.zeros((ntest, 2*dimhidden))}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print(\"  TEST ACCURACY: %.3f\" % (test_acc))\n",
    "print(\"OPTIMIZATION FINISHED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:05:49.580931Z",
     "start_time": "2019-01-16T04:05:49.230639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WITH [24] SEQS, TEST ACCR IS [0.624]\n",
      " WITH [25] SEQS, TEST ACCR IS [0.798]\n",
      " WITH [26] SEQS, TEST ACCR IS [0.934]\n",
      " WITH [27] SEQS, TEST ACCR IS [0.971]\n",
      " WITH [28] SEQS, TEST ACCR IS [0.978]\n"
     ]
    }
   ],
   "source": [
    "# What if we use smaller number of seqs?\n",
    "for _nsteps in [24, 25, 26, 27, 28]:\n",
    "    # TEST WITH TRUNCATED SEQS\n",
    "    testimgs = testimgs.reshape((ntest, nsteps, diminput))\n",
    "    testimgs_trucated = np.zeros(testimgs.shape)\n",
    "    testimgs_trucated[:, 28-_nsteps:] = testimgs[:, :_nsteps, :]\n",
    "    feeds = {x: testimgs_trucated, y: testlabels,\n",
    "             istate: np.zeros((ntest, 2*dimhidden))}\n",
    "    test_acc = sess.run(accr, feed_dict=feeds)\n",
    "    print(\" WITH [%d] SEQS, TEST ACCR IS [%.3f]\"\n",
    "          % (_nsteps, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inside RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:06:41.145610Z",
     "start_time": "2019-01-16T04:06:41.133885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'xtest' is (5, 784)\n"
     ]
    }
   ],
   "source": [
    "# Inputs to the RNN\n",
    "batch_size = 5\n",
    "xtest, _ = MNIST.test.next_batch(batch_size)\n",
    "print(\"Shape of 'xtest' is %s\" % (xtest.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:06:57.003019Z",
     "start_time": "2019-01-16T04:06:56.999408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is: [5]\n",
      "Shape of 'xtest1' is (5, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Reshaped inputs\n",
    "xtest1 = xtest.reshape((batch_size, nsteps, diminput))    # (5, 28, 28)\n",
    "print(\"Batch size is: [%d]\" % (batch_size))\n",
    "print(\"Shape of 'xtest1' is %s\" % (xtest1.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:07:34.643475Z",
     "start_time": "2019-01-16T04:07:34.640556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feeds (or feed_dict)\n",
    "feeds = {x: xtest1, istate: np.zeros((batch_size, 2*dimhidden))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:08:01.199011Z",
     "start_time": "2019-01-16T04:08:01.175006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'rnnout_X' is (140, 28)\n"
     ]
    }
   ],
   "source": [
    "# Indivisual input to the LSTM\n",
    "rnnout_X = sess.run(myrnn['X'], feed_dict=feeds)\n",
    "print(\"Shape of 'rnnout_X' is %s\" % (rnnout_X.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:08:27.418219Z",
     "start_time": "2019-01-16T04:08:27.391223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'rnnout_H' is (140, 128)\n"
     ]
    }
   ],
   "source": [
    "# Intermediate state (or hidden/cell state?)\n",
    "rnnout_H = sess.run(myrnn['H'], feed_dict=feeds)\n",
    "print(\"Shape of 'rnnout_H' is %s\" % (rnnout_H.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:08:52.503381Z",
     "start_time": "2019-01-16T04:08:52.465058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'rnnout_Hsplit' is <class 'list'>\n",
      "Length of 'rnnout_Hsplit' is 28 and the shape of each item is (5, 128)\n"
     ]
    }
   ],
   "source": [
    "# Actual input to LSTM(list)\n",
    "rnnout_Hsplit = sess.run(myrnn['Hsplit'], feed_dict=feeds)\n",
    "print(\"Type of 'rnnout_Hsplit' is %s\" % (type(rnnout_Hsplit)))\n",
    "print(\"Length of 'rnnout_Hsplit' is %s and the shape of each item is %s\"\n",
    "      % (len(rnnout_Hsplit), rnnout_Hsplit[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:09:12.713649Z",
     "start_time": "2019-01-16T04:09:12.594123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'rnnout_LSTM_O' is <class 'list'>\n",
      "Length of 'rnnout_LSTM_O' is 28 and the shape of each item is (5, 128)\n"
     ]
    }
   ],
   "source": [
    "# Output from the LSTM(list)\n",
    "rnnout_LSTM_O = sess.run(myrnn['LSTM_O'], feed_dict=feeds)\n",
    "print(\"Type of 'rnnout_LSTM_O' is %s\" % (type(rnnout_LSTM_O)))\n",
    "print(\"Length of 'rnnout_LSTM_O' is %s and the shape of each item is %s\"\n",
    "      % (len(rnnout_LSTM_O), rnnout_LSTM_O[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T04:09:29.994454Z",
     "start_time": "2019-01-16T04:09:29.880842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'rnnout_O' is (5, 10)\n"
     ]
    }
   ],
   "source": [
    "# Final prediction\n",
    "rnnout_O = sess.run(myrnn['O'], feed_dict=feeds)\n",
    "print(\"Shape of 'rnnout_O' is %s\" % (rnnout_O.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 465,
   "position": {
    "height": "487px",
    "left": "1342px",
    "right": "20px",
    "top": "120px",
    "width": "491px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
