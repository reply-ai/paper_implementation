{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:07.116870Z",
     "start_time": "2019-01-16T14:08:07.114763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8 ENCODING\n"
     ]
    }
   ],
   "source": [
    "## Specify file encoding type in python\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "print (\"UTF-8 ENCODING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:07.173217Z",
     "start_time": "2019-01-16T14:08:07.117662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n"
     ]
    }
   ],
   "source": [
    "import chardet # https://github.com/chardet/chardet\n",
    "import glob\n",
    "import codecs\n",
    "import sys\n",
    "import os\n",
    "from TextLoader import *\n",
    "from Hangulpy import *\n",
    "print (\"PACKAGES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:07.182033Z",
     "start_time": "2019-01-16T14:08:07.174927Z"
    }
   },
   "outputs": [],
   "source": [
    "## Convert UTF-8 encoded txt file\n",
    "\n",
    "def conv_file(fromfile, tofile):\n",
    "    with open(fromfile, \"rb\") as f:\n",
    "        sample_text=f.read(10240)\n",
    "    pred = chardet.detect(sample_text)\n",
    "    if not pred['encoding'].upper() in ('EUC-KR', 'UTF-8', 'CP949', 'UTF-16LE'):\n",
    "        print(\"WARNING! Unknown encoding! : %s = %s\" % (fromfile, pred['encoding']))\n",
    "        pred['encoding'] = \"CP949\" # 못찾으면 기본이 CP949\n",
    "        formfile = fromfile + \".unknown\"\n",
    "    elif pred['confidence'] < 0.9:\n",
    "        print (\"WARNING! Unsured encofing! : %s = %s / %s\")\n",
    "        % (fromfile, pred['confidence'], pred['encoding'])\n",
    "        formfile = fromfile + \".notsure\"\n",
    "    with codecs.open(fromfile, \"r\", encoding=pred['encoding'], errors=\"ignore\") as f:\n",
    "        with codecs.open(tofile, \"w+\", encoding=\"utf-8\") as t:\n",
    "            all_text = f.read()\n",
    "            t.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:07.264028Z",
     "start_time": "2019-01-16T14:08:07.184158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF8-CONVERTING DONE\n",
      " [./data/ninedreams_utf8.txt] IS GENERATED\n"
     ]
    }
   ],
   "source": [
    "## Generate UTF-8 encoded file\n",
    "\n",
    "# SOURCE TXT FILE\n",
    "fromfile = \"./data/ninedreams.txt\"\n",
    "# TARGET TXT FILE\n",
    "tofile   = \"./data/ninedreams_utf8.txt\"\n",
    "conv_file(fromfile, tofile)\n",
    "print (\"UTF8-CONVERTING DONE\")\n",
    "print (\" [%s] IS GENERATED\" % (tofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:07.267952Z",
     "start_time": "2019-01-16T14:08:07.265010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION READY\n"
     ]
    }
   ],
   "source": [
    "## Decompose Hangul (VERY IMPORTANT)\n",
    "\n",
    "def dump_file(filename):\n",
    "    result=u\"\" # <= UNICODE STRING \n",
    "    with codecs.open(filename,\"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = tuple(line)\n",
    "            result = result + decompose_text(line)\n",
    "    return result\n",
    "print (\"FUNCTION READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:08.090844Z",
     "start_time": "2019-01-16T14:08:07.268889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./data/ninedreams_utf8.txt done\n",
      "\n",
      "\n",
      "  ㅎㅏㄴᴥㄱㅜㄱᴥ ㄱㅜㄱᴥㅁㅜㄴᴥㅎㅏㄱᴥㅅㅏᴥㅅㅏㅇᴥ ㅇㅕㅇᴥㅇㅝㄴᴥㅎㅣᴥ ㅂㅣㅊᴥㄴㅏㄹᴥ ㅁㅕㅇᴥㅈㅏㄱᴥ\n",
      "  ㄱㅜᴥㅇㅜㄴᴥㅁㅗㅇᴥ\n",
      "\n",
      "\n",
      "  ㅈㅣᴥㅇㅡㄴᴥㅇㅣᴥ:ㄱㅣㅁᴥㅁㅏㄴᴥ\n"
     ]
    }
   ],
   "source": [
    "## For Python2 & Python3 compatibility...\n",
    "\n",
    "if sys.version_info.major == 2:\n",
    "    parsed_txt = dump_file(tofile).encode(\"utf8\") \n",
    "else:\n",
    "    parsed_txt = dump_file(tofile) \n",
    "\n",
    "print (\"Parsing %s done\" % (tofile))\n",
    "# PRINT FIRST 100 CHARACTERS\n",
    "print (parsed_txt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:08.096958Z",
     "start_time": "2019-01-16T14:08:08.091985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to a txt file\n",
      "<_io.TextIOWrapper name='data/input.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/input.txt\", \"w\") as text_file:\n",
    "    text_file.write(parsed_txt)\n",
    "print (\"Saved to a txt file\")\n",
    "print (text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:08:08.114574Z",
     "start_time": "2019-01-16T14:08:08.098070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 ㅏㅇ사ㅣ ㅇㅕ나ㅕㅇㅛㄱㅇㄹㅆ닿ㄹㄴ시ㅏ항곤ㅛ젆 샘ㄶㅡ니.젆ㅓ앉ㅏ뤝ㅡㄴ짉 읐?ㄴ히ㅇ\n"
     ]
    }
   ],
   "source": [
    "## Compose hangul character from phoneme\n",
    "data=[u'\\u3147', u'\\u3157', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3139', u'\\u1d25'\n",
    "      , u' ', u'\\u314f', u'\\u3147', u'\\u3145', u'\\u314f', u'\\u1d25', u'\\u1d25'\n",
    "      , u'\\u3163', u'\\u1d25', u' ', u'\\u3147', u'\\u1d25', u'\\u3155', u'\\u1d25'\n",
    "      , u'\\u3134', u'\\u314f', u'\\u1d25', u'\\u3155', u'\\u3147', u'\\u1d25'\n",
    "      , u'\\u315b', u'\\u3131', u'\\u1d25', u'\\u3147', u'\\u3139', u'\\u3146'\n",
    "      , u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u314e', u'\\u3139', u'\\u1d25'\n",
    "      , u'\\u3134', u'\\u1d25', u'\\u3145', u'\\u3163', u'\\u1d25', u'\\u1d25'\n",
    "      , u'\\u314f', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u3147', u'\\u3131'\n",
    "      , u'\\u3157', u'\\u3134', u'\\u1d25', u'\\u1d25', u'\\u315b', u'\\u1d25'\n",
    "      , u'\\u3148', u'\\u3153', u'\\u3136', u'\\u1d25', u' ', u'\\u3145', u'\\u3150'\n",
    "      , u'\\u3141', u'\\u3136', u'\\u3161', u'\\u3134', u'\\u3163', u'\\u1d25', u'.'\n",
    "      , u'\\u3148', u'\\u3153', u'\\u3134', u'\\u314e', u'\\u3153', u'\\u1d25', u'\\u1d25'\n",
    "      , u'\\u3147', u'\\u314f', u'\\u3134', u'\\u3148', u'\\u314f', u'\\u3139', u'\\u315d'\n",
    "      , u'\\u314c', u'\\u1d25', u'\\u3161', u'\\u3134', u'\\u3148', u'\\u3163', u'\\u313a'\n",
    "      , u'\\u1d25', u' ', u'\\u3147', u'\\u3161', u'\\u3146', u'\\u1d25', u'?', u'\\u3134'\n",
    "      , u'\\u1d25', u'\\u314e', u'\\u3163', u'\\u1d25', u'\\u3147', u'\\u3148', u'\\u314f'\n",
    "      ]\n",
    "print(automata(\"\".join(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:09:51.955664Z",
     "start_time": "2019-01-16T14:09:51.813233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading text file\n"
     ]
    }
   ],
   "source": [
    "## Generate \"vocab.pkl\" and \"data.npy\" in \"data/\" FROM \"data/input.txt\"\n",
    "data_dir    = \"data/\"\n",
    "batch_size  = 50\n",
    "seq_length  = 50\n",
    "data_loader = TextLoader(data_dir, batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:10:07.689219Z",
     "start_time": "2019-01-16T14:10:07.684970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of 'data_loader' is <class 'dict'>, length is 75\n"
     ]
    }
   ],
   "source": [
    "## data_loader\n",
    "print( \"type of 'data_loader' is %s, length is %d\" % (type(data_loader.vocab), len(data_loader.vocab)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:10:43.169715Z",
     "start_time": "2019-01-16T14:10:43.166132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader.vocab looks like \n",
      "{'ᴥ': 0, ' ': 1, 'ㅇ': 2, 'ㅏ': 3, 'ㄴ': 4, 'ㄹ': 5, 'ㅣ': 6, 'ㄱ': 7, 'ㅡ': 8, 'ㅗ': 9, 'ㅅ': 10, 'ㅓ': 11, 'ㅁ': 12, 'ㄷ': 13, 'ㅎ': 14, 'ㅈ': 15, 'ㅜ': 16, 'ㅂ': 17, 'ㅕ': 18, '\\n': 19, 'ㅔ': 20, 'ㅐ': 21, 'ㅆ': 22, 'ㅊ': 23, '.': 24, 'ㅢ': 25, 'ㅘ': 26, ',': 27, '\"': 28, 'ㄲ': 29, 'ㅌ': 30, 'ㅍ': 31, 'ㄸ': 32, 'ㅚ': 33, 'ㅑ': 34, 'ㅟ': 35, 'ㅝ': 36, 'ㅠ': 37, 'ㅛ': 38, 'ㅖ': 39, 'ㅉ': 40, '?': 41, 'ㅋ': 42, 'ㅄ': 43, 'ㄶ': 44, '(': 45, ')': 46, 'ㅃ': 47, 'ㄺ': 48, \"'\": 49, 'ㄵ': 50, 'ㅀ': 51, '!': 52, 'ㅙ': 53, 'ㄼ': 54, 'ㄻ': 55, 'ㄿ': 56, ':': 57, '1': 58, '6': 59, '2': 60, 'ㄳ': 61, 'ㅞ': 62, '9': 63, '5': 64, '-': 65, '4': 66, '3': 67, '8': 68, '7': 69, '_': 70, 'ㄾ': 71, 'ㅒ': 72, '0': 73, '>': 74} \n"
     ]
    }
   ],
   "source": [
    "## data_loader.vocab\n",
    "print (\"data_loader.vocab looks like \\n%s \" % (data_loader.vocab,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:11:13.272359Z",
     "start_time": "2019-01-16T14:11:13.269261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of 'data_loader.chars' is <class 'tuple'>, length is 75\n"
     ]
    }
   ],
   "source": [
    "## data_loader.chars\n",
    "print ( \"type of 'data_loader.chars' is %s, length is %d\" \n",
    "       % (type(data_loader.chars), len(data_loader.chars)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:11:54.249888Z",
     "start_time": "2019-01-16T14:11:54.245781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader.chars looks like \n",
      "('ᴥ', ' ', 'ㅇ', 'ㅏ', 'ㄴ', 'ㄹ', 'ㅣ', 'ㄱ', 'ㅡ', 'ㅗ', 'ㅅ', 'ㅓ', 'ㅁ', 'ㄷ', 'ㅎ', 'ㅈ', 'ㅜ', 'ㅂ', 'ㅕ', '\\n', 'ㅔ', 'ㅐ', 'ㅆ', 'ㅊ', '.', 'ㅢ', 'ㅘ', ',', '\"', 'ㄲ', 'ㅌ', 'ㅍ', 'ㄸ', 'ㅚ', 'ㅑ', 'ㅟ', 'ㅝ', 'ㅠ', 'ㅛ', 'ㅖ', 'ㅉ', '?', 'ㅋ', 'ㅄ', 'ㄶ', '(', ')', 'ㅃ', 'ㄺ', \"'\", 'ㄵ', 'ㅀ', '!', 'ㅙ', 'ㄼ', 'ㄻ', 'ㄿ', ':', '1', '6', '2', 'ㄳ', 'ㅞ', '9', '5', '-', '4', '3', '8', '7', '_', 'ㄾ', 'ㅒ', '0', '>') \n"
     ]
    }
   ],
   "source": [
    "## char index -> char\n",
    "print (\"data_loader.chars looks like \\n%s \" % (data_loader.chars,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T14:12:09.963828Z",
     "start_time": "2019-01-16T14:12:09.957188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00]     (00)\n",
      "[01]     (01)\n",
      "[02]     (02)\n",
      "[03]   ㅏ (03)\n",
      "[04]     (04)\n",
      "[05]     (05)\n",
      "[06]   ㅣ (06)\n",
      "[07]     (07)\n",
      "[08]   ㅡ (08)\n",
      "[09]   ㅗ (09)\n",
      "[10]     (10)\n",
      "[11]   ㅓ (11)\n",
      "[12]     (12)\n",
      "[13]     (13)\n",
      "[14]     (14)\n",
      "[15]     (15)\n",
      "[16]   ㅜ (16)\n",
      "[17]     (17)\n",
      "[18]   ㅕ (18)\n",
      "[19]   \n",
      " (19)\n",
      "[20]   ㅔ (20)\n",
      "[21]   ㅐ (21)\n",
      "[22]     (22)\n",
      "[23]     (23)\n",
      "[24]   . (24)\n",
      "[25]   ㅢ (25)\n",
      "[26]   ㅘ (26)\n",
      "[27]   , (27)\n",
      "[28]   \" (28)\n",
      "[29]     (29)\n",
      "[30]     (30)\n",
      "[31]     (31)\n",
      "[32]     (32)\n",
      "[33]   ㅚ (33)\n",
      "[34]   ㅑ (34)\n",
      "[35]   ㅟ (35)\n",
      "[36]   ㅝ (36)\n",
      "[37]   ㅠ (37)\n",
      "[38]   ㅛ (38)\n",
      "[39]   ㅖ (39)\n",
      "[40]     (40)\n",
      "[41]   ? (41)\n",
      "[42]     (42)\n",
      "[43]   ㅄ (43)\n",
      "[44]   ㄶ (44)\n",
      "[45]   ( (45)\n",
      "[46]   ) (46)\n",
      "[47]     (47)\n",
      "[48]   ㄺ (48)\n",
      "[49]   ' (49)\n",
      "[50]   ㄵ (50)\n",
      "[51]   ㅀ (51)\n",
      "[52]   ! (52)\n",
      "[53]   ㅙ (53)\n",
      "[54]   ㄼ (54)\n",
      "[55]   ㄻ (55)\n",
      "[56]   ㄿ (56)\n",
      "[57]   : (57)\n",
      "[58]   1 (58)\n",
      "[59]   6 (59)\n",
      "[60]   2 (60)\n",
      "[61]   ㄳ (61)\n",
      "[62]   ㅞ (62)\n",
      "[63]   9 (63)\n",
      "[64]   5 (64)\n",
      "[65]   - (65)\n",
      "[66]   4 (66)\n",
      "[67]   3 (67)\n",
      "[68]   8 (68)\n",
      "[69]   7 (69)\n",
      "[70]   _ (70)\n",
      "[71]   ㄾ (71)\n",
      "[72]   ㅒ (72)\n",
      "[73]   0 (73)\n",
      "[74]   > (74)\n"
     ]
    }
   ],
   "source": [
    "for i, char in enumerate(data_loader.chars):\n",
    "    # GET INDEX OF THE CHARACTER\n",
    "    idx = data_loader.vocab[char]\n",
    "    print (\"[%02d] %03s (%02d)\" \n",
    "           % (i, automata(\"\".join(char)), idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
